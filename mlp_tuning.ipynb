{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNu4EjrtDa2iDBfSkxyCalM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "3aBXBKnJcjp1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import ge\n",
        "import numpy as np\n",
        "from typing import Callable, List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Ellipse\n",
        "\n",
        "class CMAES():\n",
        "    def __init__(self, arg_names: List[str], ave_vec: List[float], sigma=1.0, max_iter=100, population=None, mu=None, fixed_args=None):\n",
        "        self.arg_names = arg_names\n",
        "        self.fixed_args = fixed_args or {}\n",
        "        self.dim = len(ave_vec)\n",
        "        self.max_iter = max_iter\n",
        "        # 個体数と選抜数\n",
        "        self.population = population if population else int(4 + 3 * np.log(self.dim))\n",
        "        self.mu = mu if mu else int(np.floor(self.population / 2))\n",
        "        # 平均値ベクトル\n",
        "        self.m = np.array(ave_vec, dtype=np.float64)\n",
        "        # 重み行列の計算(muを定義した後)\n",
        "        self.weights = self.calc_weights()\n",
        "        self.mu_eff = 1.0 / (self.weights**2).sum()\n",
        "        self.sigma = float(sigma)\n",
        "        self.C = np.identity(self.dim)\n",
        "        self.c_1 = 2.0 / ((self.dim + 1.3) ** 2 + self.mu_eff)\n",
        "        self.c_mu = min(\n",
        "        1 - self.c_1,\n",
        "        2.0 * (self.mu_eff - 2 + 1/self.mu_eff) / ((self.dim + 2) ** 2 + self.mu_eff)\n",
        "        )\n",
        "        self.chi = np.sqrt(self.dim) * (1 - 1 / (4 * self.dim) + 1 / (21 * (self.dim ** 2)))\n",
        "        self.c_c = (4 + self.mu_eff / self.dim) / (self.dim + 4 + 2 * self.mu_eff / self.dim)\n",
        "        self.c_sigma = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)\n",
        "        self.p_c = np.zeros(self.dim)\n",
        "        self.p_sigma = np.zeros(self.dim)\n",
        "        self.loss = float('inf')\n",
        "        self.best_val = None\n",
        "\n",
        "        self.history = {\n",
        "            'best_fitness': [],\n",
        "            'mean_fitness': [],\n",
        "            'worst_fitness': [],\n",
        "            'mean_vector': [],\n",
        "            'sigma': [],\n",
        "            'eigenvalues': [],\n",
        "            'populations': []  # 各世代の全個体\n",
        "        }\n",
        "\n",
        "    def sample(self) -> List[float]:\n",
        "        \"\"\"多次元正規分布からサンプリングをする\"\"\"\n",
        "        arr = np.random.multivariate_normal(mean=self.m, cov=self.C, size=self.dim)\n",
        "        arr = arr.tolist()[0]\n",
        "        return arr\n",
        "\n",
        "    def calc_weights(self):\n",
        "        \"\"\"対数重みを計算する\"\"\"\n",
        "        raw_weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n",
        "        return raw_weights / raw_weights.sum()\n",
        "\n",
        "    def matrix_inverse_sqrt(self):\n",
        "        # 固有値分解\n",
        "        eigvals, eigvecs = np.linalg.eigh(self.C)\n",
        "\n",
        "        # 数値安定性のために微小値で下限をつける\n",
        "        eigvals = np.maximum(eigvals, 1e-20)\n",
        "\n",
        "        # Λ^{-1/2}\n",
        "        D_inv_sqrt = np.diag(1.0 / np.sqrt(eigvals))\n",
        "\n",
        "        # C^{-1/2} = Q Λ^{-1/2} Q^T\n",
        "        C_inv_sqrt = eigvecs @ D_inv_sqrt @ eigvecs.T\n",
        "        return C_inv_sqrt\n",
        "\n",
        "    def compute_d_sigma(self):\n",
        "        return 1 + self.c_sigma + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1)\n",
        "\n",
        "    def debug(self):\n",
        "        print(f\"weights: {self.weights}\")\n",
        "        print(f\"\")\n",
        "\n",
        "    def record_history(self, fitness_values, population):\n",
        "        self.history['best_fitness'].append(np.min(fitness_values))\n",
        "        self.history['mean_fitness'].append(np.mean(fitness_values))\n",
        "        self.history['worst_fitness'].append(np.max(fitness_values))\n",
        "        self.history['mean_vector'].append(self.m.copy())\n",
        "        self.history['sigma'].append(self.sigma)\n",
        "        eigenvals, _ = np.linalg.eigh(self.C)\n",
        "        self.history['eigenvalues'].append(eigenvals.copy())\n",
        "        self.history['populations'].append(population.copy())\n",
        "\n",
        "    def opt(self, f: Callable) -> Tuple[float, List[float]]:\n",
        "        dim = self.dim\n",
        "        mu_eff = self.mu_eff\n",
        "\n",
        "        # 選抜を行うループ\n",
        "        for gen in range(self.max_iter):\n",
        "            print(f\"{'='*5}{gen+1}世代目{'='*5}\")\n",
        "            # 個体集合を生成\n",
        "            group: List[List[float]] = []\n",
        "            for _ in range(self.population):\n",
        "                group.append(self.sample())\n",
        "\n",
        "            # 関数に入力する\n",
        "            scores: List[Tuple[float, List[float]]] = []\n",
        "            for x in group:\n",
        "                arg_dict = {name: val for name, val in zip(self.arg_names, x)}\n",
        "                arg_dict.update(self.fixed_args)\n",
        "                current_loss = f(**arg_dict)\n",
        "                scores.append((current_loss, x))\n",
        "\n",
        "            # 損失で昇順に並べ替える\n",
        "            scores.sort(key=lambda x: x[0])\n",
        "\n",
        "            # 暫定出力値の更新\n",
        "            if self.loss > scores[0][0]:\n",
        "                # print(f\"DEBUG loss: {scores[0][0]}\")\n",
        "                self.loss = scores[0][0]\n",
        "                self.best_val = scores[0][1]\n",
        "                print(f\"最小値の更新: \")\n",
        "                print(f\"値: {self.loss}\")\n",
        "                print(f\"ベクトル: {self.best_val}\")\n",
        "\n",
        "            fitness_values = np.array([i[0] for i in scores])\n",
        "            population = np.array([i[1] for i in scores])\n",
        "            # print(f\"min(fitness_values): {np.min(fitness_values)}\")\n",
        "            self.record_history(fitness_values, population)\n",
        "\n",
        "            # self.muの個体を取り出す\n",
        "            elites = scores[:self.mu]\n",
        "            elites = np.array([i[1] for i in elites])\n",
        "\n",
        "            # 平均値ベクトルの更新\n",
        "            m_old = self.m\n",
        "            self.m = self.weights @ elites\n",
        "            # print(f\"m: {self.m}\")\n",
        "\n",
        "            # 共分散行列のランクmu更新\n",
        "            C_mu = np.zeros((dim, dim))\n",
        "            for i in range(self.mu):\n",
        "                x = np.array(elites[i])\n",
        "                y_i = x - m_old\n",
        "                C_mu = C_mu + self.weights[i] * (np.outer(y_i, y_i) / self.mu)\n",
        "\n",
        "            # print(f\"[DEBUG] C_mu: \\n{C_mu}\")\n",
        "            C_mu /= self.sigma ** 2\n",
        "\n",
        "            # ステップサイズσの更新処理\n",
        "            y = (self.m - m_old) / self.sigma\n",
        "            p_sigma = (1 - self.c_sigma) * self.p_sigma\n",
        "            p_sigma += np.sqrt(1 - (1 - self.c_sigma) ** 2) * mu_eff * (self.matrix_inverse_sqrt() @ y)\n",
        "\n",
        "            p_sigma_norm = np.linalg.norm(p_sigma)\n",
        "            self.sigma = self.sigma * np.exp(\n",
        "                (self.c_sigma / self.compute_d_sigma())\n",
        "                * (p_sigma_norm / self.chi - 1)\n",
        "            )\n",
        "            self.p_sigma = p_sigma\n",
        "\n",
        "            \"\"\"\n",
        "            # ステップサイズが多すぎるときにCの更新を止める\n",
        "            left = np.sqrt((self.p_sigma ** 2).sum()) / np.sqrt(1 - (1 - self.c_sigma) ** (2 * (gen+1)))\n",
        "            right = (1.4 + 2 / (self.dim + 1)) * self.chi\n",
        "            hsigma = 1 if left < right else 0\n",
        "            d_hsigma = (1 - hsigma) * self.c_c * (2 - self.c_c)\n",
        "            \"\"\"\n",
        "\n",
        "            # 共分散行列のランク1更新\n",
        "            self.p_c = (1 - self.c_c) * self.p_c + np.sqrt(1 - (1 - self.c_c) ** 2) * np.sqrt(mu_eff) * y\n",
        "            C_1 = np.outer(self.p_c, self.p_c)\n",
        "\n",
        "            # 共分散行列の更新\n",
        "            C_new = (1 - self.c_mu - self.c_1) * self.C + self.c_mu * C_mu + self.c_1 * C_1\n",
        "            self.C = C_new\n",
        "\n",
        "        # print(f\"[DEBUG] m: {m}\")\n",
        "        return (self.loss, self.best_val)\n",
        "\n",
        "    def plot_convergence(self, figsize=(12, 8), ans=None):\n",
        "        \"\"\"収束履歴をプロット\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
        "\n",
        "        # 適応度の履歴\n",
        "        generations = range(len(self.history['best_fitness']))\n",
        "        axes[0, 0].semilogy(generations, self.history['best_fitness'], 'b-', label='Best')\n",
        "        axes[0, 0].semilogy(generations, self.history['mean_fitness'], 'g-', label='Mean')\n",
        "        axes[0, 0].semilogy(generations, self.history['worst_fitness'], 'r-', label='Worst')\n",
        "        axes[0, 0].set_xlabel('Generation')\n",
        "        axes[0, 0].set_ylabel('Fitness')\n",
        "        axes[0, 0].set_title('Fitness Evolution')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True)\n",
        "\n",
        "        # ステップサイズの履歴\n",
        "        axes[0, 1].semilogy(generations, self.history['sigma'], 'purple')\n",
        "        axes[0, 1].set_xlabel('Generation')\n",
        "        axes[0, 1].set_ylabel('Step Size (σ)')\n",
        "        axes[0, 1].set_title('Step Size Evolution')\n",
        "        axes[0, 1].grid(True)\n",
        "\n",
        "        if self.dim == 2:\n",
        "            mean_vectors = np.array(self.history['mean_vector'])\n",
        "            axes[1, 0].plot(mean_vectors[:, 0], mean_vectors[:, 1], 'o-', markersize=3)\n",
        "            axes[1, 0].plot(mean_vectors[0, 0], mean_vectors[0, 1], 'go', markersize=8, label='Start')\n",
        "            axes[1, 0].plot(mean_vectors[-1, 0], mean_vectors[-1, 1], 'ro', markersize=8, label='End')\n",
        "            axes[1, 0].set_xlabel(self.arg_names[0])\n",
        "            axes[1, 0].set_ylabel(self.arg_names[1])\n",
        "            axes[1, 0].set_title('Mean Vector Trajectory')\n",
        "            axes[1, 0].legend()\n",
        "            axes[1, 0].grid(True)\n",
        "            if ans:\n",
        "                axes[1, 0].plot(ans[0], ans[1], 'r*', markersize=8, label='Answer')\n",
        "\n",
        "        eigenvalues = np.array(self.history['eigenvalues'])\n",
        "        for i in range(self.dim):\n",
        "            axes[1, 1].semilogy(generations, eigenvalues[:, i], label=f'λ{i+1}')\n",
        "        axes[1, 1].set_xlabel('Generation')\n",
        "        axes[1, 1].set_ylabel('Eigenvalues')\n",
        "        axes[1, 1].set_title('Covariance Matrix Eigenvalues')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_2d_optimization(self, objective_func, xlim=(-3, 3), ylim=(-3, 3), figsize=(10, 8)):\n",
        "        \"\"\"2次元最適化の可視化\"\"\"\n",
        "        if self.dim != 2:\n",
        "            print(\"2次元問題のみ対応\")\n",
        "            return\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "        # 等高線プロット\n",
        "        x = np.linspace(xlim[0], xlim[1], 100)\n",
        "        y = np.linspace(ylim[0], ylim[1], 100)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "        Z = np.zeros_like(X)\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            for j in range(X.shape[1]):\n",
        "                Z[i, j] = objective_func(X[i, j], Y[i, j])\n",
        "\n",
        "        contour = ax.contour(X, Y, Z, levels=20, alpha=0.6)\n",
        "        ax.clabel(contour, inline=True, fontsize=8)\n",
        "\n",
        "        # 最適化軌跡\n",
        "        mean_vectors = np.array(self.history['mean_vector'])\n",
        "        ax.plot(mean_vectors[:, 0], mean_vectors[:, 1], 'r-o', markersize=4, linewidth=2, label='Mean trajectory')\n",
        "\n",
        "        # 最終世代の個体群と分散楕円\n",
        "        if self.history['populations']:\n",
        "            final_pop = self.history['populations'][-1]\n",
        "            ax.scatter(final_pop[:, 0], final_pop[:, 1], alpha=0.6, s=20, label='Final population')\n",
        "\n",
        "            # 分散楕円\n",
        "            mean = mean_vectors[-1]\n",
        "            cov = self.C * (self.sigma ** 2)\n",
        "            eigenvals, eigenvecs = np.linalg.eigh(cov)\n",
        "\n",
        "            # 95%信頼楕円\n",
        "            angle = np.degrees(np.arctan2(*eigenvecs[:, 0][::-1]))\n",
        "            width, height = 2 * np.sqrt(eigenvals) * 2.448  # 95%信頼区間\n",
        "\n",
        "            ellipse = Ellipse(mean, width, height, angle=angle,\n",
        "                            facecolor='none', edgecolor='red', linewidth=2, alpha=0.8)\n",
        "            ax.add_patch(ellipse)\n",
        "\n",
        "        ax.set_xlabel(self.arg_names[0])\n",
        "        ax.set_ylabel(self.arg_names[1])\n",
        "        ax.set_title('2D Optimization Visualization')\n",
        "        ax.legend()\n",
        "        ax.grid(True)\n",
        "        ax.set_xlim(xlim)\n",
        "        ax.set_ylim(ylim)\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "WZlR6g1RQdQk"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist_data():\n",
        "  \"\"\"\n",
        "  MNISTをロードして前処理\n",
        "  \"\"\"\n",
        "  mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "  X, y = mnist.data, mnist.target.astype(int)\n",
        "  # (0-255) -> (0, 1)\n",
        "  X = X / 255.0\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      X, y, test_size=0.2, random_state=42, stratify=y\n",
        "  )\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(\n",
        "      X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        "  )\n",
        "\n",
        "  print(f\"訓練データ: {X_train.shape}\")\n",
        "  print(f\"検証データ: {X_val.shape}\")\n",
        "  print(f\"テストデータ: {X_test.shape}\")\n",
        "\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "id": "CuGLetDndDsN"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(X_train, X_val, X_test, y_train, y_val, y_test, batch_size=32):\n",
        "  \"\"\"PyTorchのDataLoaderを作成\"\"\"\n",
        "  # numpy array -> Pytorch Tensor\n",
        "  X_train_tensor = torch.FloatTensor(X_train)\n",
        "  X_val_tensor = torch.FloatTensor(X_val)\n",
        "  X_test_tensor = torch.FloatTensor(X_test)\n",
        "  y_train_tensor = torch.LongTensor(y_train)\n",
        "  y_val_tensor = torch.LongTensor(y_val)\n",
        "  y_test_tensor = torch.LongTensor(y_test)\n",
        "\n",
        "  train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "  val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "  test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "g8HWXHeReiP9"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmallMLP(nn.Module):\n",
        "  def __init__(self, input_size=784, hidden_size=128, num_classes=10, dropout_rate=0.2):\n",
        "    super(SmallMLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch_size, 28, 28) → (batch_size, 784)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "ybpUCSNw7Ju4"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    2層の隠れ層を持つMLP\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=784, hidden1_size=256, hidden2_size=128,\n",
        "                 num_classes=10, dropout_rate=0.2):\n",
        "        super(TwoLayerMLP, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.fc3 = nn.Linear(hidden2_size, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # 第1隠れ層\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # 第2隠れ層\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # 出力層\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "g52uIr9BMD-8"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_smallmlp_with_params(learning_rate, hidden_size, dropout_rate,\n",
        "                     train_loader, val_loader, epochs=10):\n",
        "    \"\"\"\n",
        "    指定されたハイパーパラメータでモデルを訓練\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    # デバイスの設定\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # print(f\"Using device: {device}\")\n",
        "\n",
        "    # パラメータの制約\n",
        "    learning_rate = max(0.0001, min(0.1, learning_rate / 100))\n",
        "    hidden_size = max(32, min(512, int(hidden_size * 100)))\n",
        "    dropout_rate = max(0.0, min(0.5, dropout_rate / 100))\n",
        "\n",
        "    model = SmallMLP(hidden_size=hidden_size, dropout_rate=dropout_rate)\n",
        "    model = model.to(device)  # モデルをGPUに移動\n",
        "\n",
        "    # 訓練\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = loss.item()\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        # print(f'Epoch [{epoch+1}/{epochs}], ' f'Train Loss: {train_loss:.4f}, ' f'Time: {training_time:.2f}')\n",
        "\n",
        "    # 検証\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            # データをGPUに移動\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    accuracy = correct / total\n",
        "    print(f\"training time: {training_time:.2f}s, accuracy: {accuracy:.4f}\")\n",
        "    return -accuracy  # CMA-ESは最小化なので負の値を返す"
      ],
      "metadata": {
        "id": "u4Gd2k2T80UK"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_2lmlp_with_params(learning_rate, hidden1_size, hidden2_size, dropout_rate,\n",
        "                     train_loader, val_loader, epochs=10):\n",
        "    \"\"\"\n",
        "    指定されたハイパーパラメータでモデルを訓練\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    # デバイスの設定\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # print(f\"Using device: {device}\")\n",
        "\n",
        "    # パラメータの制約\n",
        "    learning_rate = max(0.0001, min(0.1, learning_rate))\n",
        "    hidden1_size = max(32, min(512, int(hidden1_size)))\n",
        "    hidden2_size = max(32, min(512, int(hidden2_size)))\n",
        "    dropout_rate = max(0.0, min(0.5, dropout_rate))\n",
        "\n",
        "    model = TwoLayerMLP(hidden1_size=hidden1_size, hidden2_size=hidden2_size, dropout_rate=dropout_rate)\n",
        "    model = model.to(device)  # モデルをGPUに移動\n",
        "\n",
        "    # 訓練\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = loss.item()\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        # print(f'Epoch [{epoch+1}/{epochs}], ' f'Train Loss: {train_loss:.4f}, ' f'Time: {training_time:.2f}')\n",
        "\n",
        "    # 検証\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            # データをGPUに移動\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    accuracy = correct / total\n",
        "    print(f\"訓練時間: {training_time:.2f}秒\")\n",
        "    print(f\"正解率: {accuracy}\")\n",
        "    return -accuracy  # CMA-ESは最小化なので負の値を返す"
      ],
      "metadata": {
        "id": "RIKYDDx-MqV0"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = load_mnist_data()\n",
        "train_loader, val_loader, test_loader = create_data_loaders(X_train, X_val, X_test, y_train, y_val, y_test, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmFtZNMADBOp",
        "outputId": "746a7995-4fbe-4288-8699-5238986bc787"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練データ: (44800, 784)\n",
            "検証データ: (11200, 784)\n",
            "テストデータ: (14000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_smallmlp_with_params(0.001, 256, 0.2, train_loader, val_loader, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et_-3KeDDppt",
        "outputId": "d1a54379-5c9c-4796-ef5b-5d3effaf486d"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time: 10.31s, accuracy: 0.9526\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.9525892857142857"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_2lmlp_with_params(0.005, 256, 512, 0.2, train_loader, val_loader, epochs=15)"
      ],
      "metadata": {
        "id": "HKF9PDAhMoJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efaca8f8-c9a6-427b-c3f9-deef4951f96c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練時間: 11.52秒\n",
            "正解率: 0.9733035714285714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.9733035714285714"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = [\"learning_rate\", \"hidden_size\", \"dropout_rate\"]\n",
        "fixed_args = {\"train_loader\": train_loader, \"val_loader\": val_loader, \"epochs\": 10}\n",
        "init_point = [1.0, 2.56, 2.0]\n",
        "cmaes = CMAES(arg_names=params, ave_vec=init_point, max_iter=10, fixed_args=fixed_args)"
      ],
      "metadata": {
        "id": "-yPj58m_QZ9d"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, value = cmaes.opt(train_smallmlp_with_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "3p19KZhJWAxd",
        "outputId": "d1c1fb88-8385-4572-c2d7-4fe6772c78c6"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====1世代目=====\n",
            "training time: 7.36s, accuracy: 0.9692\n",
            "training time: 6.63s, accuracy: 0.9752\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-122-2579618192.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmaes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_smallmlp_with_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-111-1397874549.py\u001b[0m in \u001b[0;36mopt\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0marg_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0marg_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-116-2187052512.py\u001b[0m in \u001b[0;36mtrain_smallmlp_with_params\u001b[0;34m(learning_rate, hidden_size, dropout_rate, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq7OI5cqhe6T",
        "outputId": "7b517c23-aae2-4b40-dd27-8b1325a94cb4"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2844775778363134, 3.4931197031262182, 0.4560618736564812]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fixed = train_smallmlp_with_params(value[0], 512, value[2], train_loader, val_loader, epochs=15)\n",
        "result = train_smallmlp_with_params(value[0], value[1], value[2], train_loader, val_loader, epochs=15)\n",
        "\n",
        "print(f\"512次元で固定: {fixed}\")\n",
        "print(f\"最適化の結果を使用: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqxZPnuYhipV",
        "outputId": "88329eed-c1ba-40f1-920c-5020f87362c8"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time: 10.56s, accuracy: 0.9811\n",
            "training time: 10.59s, accuracy: 0.9796\n",
            "512次元で固定: -0.9810714285714286\n",
            "最適化の結果を使用: -0.9795535714285715\n"
          ]
        }
      ]
    }
  ]
}