{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJAksPZhvAhNX8sz3P6Qbw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aBXBKnJcjp1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import ge\n",
        "import numpy as np\n",
        "from typing import Callable, List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Ellipse\n",
        "\n",
        "class CMAES():\n",
        "    def __init__(self, arg_names: List[str], ave_vec: List[float], sigma=1.0, max_iter=100, population=None, mu=None, fixed_args=None):\n",
        "        self.arg_names = arg_names\n",
        "        self.fixed_args = fixed_args or {}\n",
        "        self.dim = len(ave_vec)\n",
        "        self.max_iter = max_iter\n",
        "        # 個体数と選抜数\n",
        "        self.population = population if population else int(4 + 3 * np.log(self.dim))\n",
        "        self.mu = mu if mu else int(np.floor(self.population / 2))\n",
        "        # 平均値ベクトル\n",
        "        self.m = np.array(ave_vec, dtype=np.float64)\n",
        "        # 重み行列の計算(muを定義した後)\n",
        "        self.weights = self.calc_weights()\n",
        "        self.mu_eff = 1.0 / (self.weights**2).sum()\n",
        "        self.sigma = float(sigma)\n",
        "        self.C = np.identity(self.dim)\n",
        "        self.c_1 = 2.0 / ((self.dim + 1.3) ** 2 + self.mu_eff)\n",
        "        self.c_mu = min(\n",
        "        1 - self.c_1,\n",
        "        2.0 * (self.mu_eff - 2 + 1/self.mu_eff) / ((self.dim + 2) ** 2 + self.mu_eff)\n",
        "        )\n",
        "        self.chi = np.sqrt(self.dim) * (1 - 1 / (4 * self.dim) + 1 / (21 * (self.dim ** 2)))\n",
        "        self.c_c = (4 + self.mu_eff / self.dim) / (self.dim + 4 + 2 * self.mu_eff / self.dim)\n",
        "        self.c_sigma = (self.mu_eff + 2) / (self.dim + self.mu_eff + 5)\n",
        "        self.p_c = np.zeros(self.dim)\n",
        "        self.p_sigma = np.zeros(self.dim)\n",
        "        self.loss = float('inf')\n",
        "        self.best_val = None\n",
        "\n",
        "        self.history = {\n",
        "            'best_fitness': [],\n",
        "            'mean_fitness': [],\n",
        "            'worst_fitness': [],\n",
        "            'mean_vector': [],\n",
        "            'sigma': [],\n",
        "            'eigenvalues': [],\n",
        "            'populations': []  # 各世代の全個体\n",
        "        }\n",
        "\n",
        "    def sample(self) -> List[float]:\n",
        "        \"\"\"多次元正規分布からサンプリングをする\"\"\"\n",
        "        arr = np.random.multivariate_normal(mean=self.m, cov=self.C, size=self.dim)\n",
        "        arr = arr.tolist()[0]\n",
        "        return arr\n",
        "\n",
        "    def calc_weights(self):\n",
        "        \"\"\"対数重みを計算する\"\"\"\n",
        "        raw_weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n",
        "        return raw_weights / raw_weights.sum()\n",
        "\n",
        "    def matrix_inverse_sqrt(self):\n",
        "        # 固有値分解\n",
        "        eigvals, eigvecs = np.linalg.eigh(self.C)\n",
        "\n",
        "        # 数値安定性のために微小値で下限をつける\n",
        "        eigvals = np.maximum(eigvals, 1e-20)\n",
        "\n",
        "        # Λ^{-1/2}\n",
        "        D_inv_sqrt = np.diag(1.0 / np.sqrt(eigvals))\n",
        "\n",
        "        # C^{-1/2} = Q Λ^{-1/2} Q^T\n",
        "        C_inv_sqrt = eigvecs @ D_inv_sqrt @ eigvecs.T\n",
        "        return C_inv_sqrt\n",
        "\n",
        "    def compute_d_sigma(self):\n",
        "        return 1 + self.c_sigma + 2 * max(0, np.sqrt((self.mu_eff - 1) / (self.dim + 1)) - 1)\n",
        "\n",
        "    def debug(self):\n",
        "        print(f\"weights: {self.weights}\")\n",
        "        print(f\"\")\n",
        "\n",
        "    def record_history(self, fitness_values, population):\n",
        "        self.history['best_fitness'].append(np.min(fitness_values))\n",
        "        self.history['mean_fitness'].append(np.mean(fitness_values))\n",
        "        self.history['worst_fitness'].append(np.max(fitness_values))\n",
        "        self.history['mean_vector'].append(self.m.copy())\n",
        "        self.history['sigma'].append(self.sigma)\n",
        "        eigenvals, _ = np.linalg.eigh(self.C)\n",
        "        self.history['eigenvalues'].append(eigenvals.copy())\n",
        "        self.history['populations'].append(population.copy())\n",
        "\n",
        "    def opt(self, f: Callable) -> Tuple[float, List[float]]:\n",
        "        dim = self.dim\n",
        "        mu_eff = self.mu_eff\n",
        "\n",
        "        # 選抜を行うループ\n",
        "        for gen in range(self.max_iter):\n",
        "            print(f\"{'='*5}{gen+1}世代目{'='*5}\")\n",
        "            # 個体集合を生成\n",
        "            group: List[List[float]] = []\n",
        "            for _ in range(self.population):\n",
        "                group.append(self.sample())\n",
        "\n",
        "            # 関数に入力する\n",
        "            scores: List[Tuple[float, List[float]]] = []\n",
        "            for x in group:\n",
        "                arg_dict = {name: val for name, val in zip(self.arg_names, x)}\n",
        "                arg_dict.update(self.fixed_args)\n",
        "                current_loss = f(**arg_dict)\n",
        "                scores.append((current_loss, x))\n",
        "\n",
        "            # 損失で昇順に並べ替える\n",
        "            scores.sort(key=lambda x: x[0])\n",
        "\n",
        "            # 暫定出力値の更新\n",
        "            if self.loss > scores[0][0]:\n",
        "                # print(f\"DEBUG loss: {scores[0][0]}\")\n",
        "                self.loss = scores[0][0]\n",
        "                self.best_val = scores[0][1]\n",
        "                print(f\"最小値の更新: \")\n",
        "                print(f\"値: {self.loss}\")\n",
        "                print(f\"ベクトル: {self.best_val}\")\n",
        "\n",
        "            fitness_values = np.array([i[0] for i in scores])\n",
        "            population = np.array([i[1] for i in scores])\n",
        "            # print(f\"min(fitness_values): {np.min(fitness_values)}\")\n",
        "            self.record_history(fitness_values, population)\n",
        "\n",
        "            # self.muの個体を取り出す\n",
        "            elites = scores[:self.mu]\n",
        "            elites = np.array([i[1] for i in elites])\n",
        "\n",
        "            # 平均値ベクトルの更新\n",
        "            m_old = self.m\n",
        "            self.m = self.weights @ elites\n",
        "            # print(f\"m: {self.m}\")\n",
        "\n",
        "            # 共分散行列のランクmu更新\n",
        "            C_mu = np.zeros((dim, dim))\n",
        "            for i in range(self.mu):\n",
        "                x = np.array(elites[i])\n",
        "                y_i = x - m_old\n",
        "                C_mu = C_mu + self.weights[i] * (np.outer(y_i, y_i) / self.mu)\n",
        "\n",
        "            # print(f\"[DEBUG] C_mu: \\n{C_mu}\")\n",
        "            C_mu /= self.sigma ** 2\n",
        "\n",
        "            # ステップサイズσの更新処理\n",
        "            y = (self.m - m_old) / self.sigma\n",
        "            p_sigma = (1 - self.c_sigma) * self.p_sigma\n",
        "            p_sigma += np.sqrt(1 - (1 - self.c_sigma) ** 2) * mu_eff * (self.matrix_inverse_sqrt() @ y)\n",
        "\n",
        "            p_sigma_norm = np.linalg.norm(p_sigma)\n",
        "            self.sigma = self.sigma * np.exp(\n",
        "                (self.c_sigma / self.compute_d_sigma())\n",
        "                * (p_sigma_norm / self.chi - 1)\n",
        "            )\n",
        "            self.p_sigma = p_sigma\n",
        "\n",
        "            \"\"\"\n",
        "            # ステップサイズが多すぎるときにCの更新を止める\n",
        "            left = np.sqrt((self.p_sigma ** 2).sum()) / np.sqrt(1 - (1 - self.c_sigma) ** (2 * (gen+1)))\n",
        "            right = (1.4 + 2 / (self.dim + 1)) * self.chi\n",
        "            hsigma = 1 if left < right else 0\n",
        "            d_hsigma = (1 - hsigma) * self.c_c * (2 - self.c_c)\n",
        "            \"\"\"\n",
        "\n",
        "            # 共分散行列のランク1更新\n",
        "            self.p_c = (1 - self.c_c) * self.p_c + np.sqrt(1 - (1 - self.c_c) ** 2) * np.sqrt(mu_eff) * y\n",
        "            C_1 = np.outer(self.p_c, self.p_c)\n",
        "\n",
        "            # 共分散行列の更新\n",
        "            C_new = (1 - self.c_mu - self.c_1) * self.C + self.c_mu * C_mu + self.c_1 * C_1\n",
        "            self.C = C_new\n",
        "\n",
        "        # print(f\"[DEBUG] m: {m}\")\n",
        "        return (self.loss, self.best_val)\n",
        "\n",
        "    def plot_convergence(self, figsize=(12, 8), ans=None):\n",
        "        \"\"\"収束履歴をプロット\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
        "\n",
        "        # 適応度の履歴\n",
        "        generations = range(len(self.history['best_fitness']))\n",
        "        axes[0, 0].semilogy(generations, self.history['best_fitness'], 'b-', label='Best')\n",
        "        axes[0, 0].semilogy(generations, self.history['mean_fitness'], 'g-', label='Mean')\n",
        "        axes[0, 0].semilogy(generations, self.history['worst_fitness'], 'r-', label='Worst')\n",
        "        axes[0, 0].set_xlabel('Generation')\n",
        "        axes[0, 0].set_ylabel('Fitness')\n",
        "        axes[0, 0].set_title('Fitness Evolution')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True)\n",
        "\n",
        "        # ステップサイズの履歴\n",
        "        axes[0, 1].semilogy(generations, self.history['sigma'], 'purple')\n",
        "        axes[0, 1].set_xlabel('Generation')\n",
        "        axes[0, 1].set_ylabel('Step Size (σ)')\n",
        "        axes[0, 1].set_title('Step Size Evolution')\n",
        "        axes[0, 1].grid(True)\n",
        "\n",
        "        if self.dim == 2:\n",
        "            mean_vectors = np.array(self.history['mean_vector'])\n",
        "            axes[1, 0].plot(mean_vectors[:, 0], mean_vectors[:, 1], 'o-', markersize=3)\n",
        "            axes[1, 0].plot(mean_vectors[0, 0], mean_vectors[0, 1], 'go', markersize=8, label='Start')\n",
        "            axes[1, 0].plot(mean_vectors[-1, 0], mean_vectors[-1, 1], 'ro', markersize=8, label='End')\n",
        "            axes[1, 0].set_xlabel(self.arg_names[0])\n",
        "            axes[1, 0].set_ylabel(self.arg_names[1])\n",
        "            axes[1, 0].set_title('Mean Vector Trajectory')\n",
        "            axes[1, 0].legend()\n",
        "            axes[1, 0].grid(True)\n",
        "            if ans:\n",
        "                axes[1, 0].plot(ans[0], ans[1], 'r*', markersize=8, label='Answer')\n",
        "\n",
        "        eigenvalues = np.array(self.history['eigenvalues'])\n",
        "        for i in range(self.dim):\n",
        "            axes[1, 1].semilogy(generations, eigenvalues[:, i], label=f'λ{i+1}')\n",
        "        axes[1, 1].set_xlabel('Generation')\n",
        "        axes[1, 1].set_ylabel('Eigenvalues')\n",
        "        axes[1, 1].set_title('Covariance Matrix Eigenvalues')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_2d_optimization(self, objective_func, xlim=(-3, 3), ylim=(-3, 3), figsize=(10, 8)):\n",
        "        \"\"\"2次元最適化の可視化\"\"\"\n",
        "        if self.dim != 2:\n",
        "            print(\"2次元問題のみ対応\")\n",
        "            return\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "        # 等高線プロット\n",
        "        x = np.linspace(xlim[0], xlim[1], 100)\n",
        "        y = np.linspace(ylim[0], ylim[1], 100)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "        Z = np.zeros_like(X)\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            for j in range(X.shape[1]):\n",
        "                Z[i, j] = objective_func(X[i, j], Y[i, j])\n",
        "\n",
        "        contour = ax.contour(X, Y, Z, levels=20, alpha=0.6)\n",
        "        ax.clabel(contour, inline=True, fontsize=8)\n",
        "\n",
        "        # 最適化軌跡\n",
        "        mean_vectors = np.array(self.history['mean_vector'])\n",
        "        ax.plot(mean_vectors[:, 0], mean_vectors[:, 1], 'r-o', markersize=4, linewidth=2, label='Mean trajectory')\n",
        "\n",
        "        # 最終世代の個体群と分散楕円\n",
        "        if self.history['populations']:\n",
        "            final_pop = self.history['populations'][-1]\n",
        "            ax.scatter(final_pop[:, 0], final_pop[:, 1], alpha=0.6, s=20, label='Final population')\n",
        "\n",
        "            # 分散楕円\n",
        "            mean = mean_vectors[-1]\n",
        "            cov = self.C * (self.sigma ** 2)\n",
        "            eigenvals, eigenvecs = np.linalg.eigh(cov)\n",
        "\n",
        "            # 95%信頼楕円\n",
        "            angle = np.degrees(np.arctan2(*eigenvecs[:, 0][::-1]))\n",
        "            width, height = 2 * np.sqrt(eigenvals) * 2.448  # 95%信頼区間\n",
        "\n",
        "            ellipse = Ellipse(mean, width, height, angle=angle,\n",
        "                            facecolor='none', edgecolor='red', linewidth=2, alpha=0.8)\n",
        "            ax.add_patch(ellipse)\n",
        "\n",
        "        ax.set_xlabel(self.arg_names[0])\n",
        "        ax.set_ylabel(self.arg_names[1])\n",
        "        ax.set_title('2D Optimization Visualization')\n",
        "        ax.legend()\n",
        "        ax.grid(True)\n",
        "        ax.set_xlim(xlim)\n",
        "        ax.set_ylim(ylim)\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "WZlR6g1RQdQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist_data():\n",
        "  \"\"\"\n",
        "  MNISTをロードして前処理\n",
        "  \"\"\"\n",
        "  mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "  X, y = mnist.data, mnist.target.astype(int)\n",
        "  # (0-255) -> (0, 1)\n",
        "  X = X / 255.0\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      X, y, test_size=0.2, random_state=42, stratify=y\n",
        "  )\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(\n",
        "      X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        "  )\n",
        "\n",
        "  print(f\"訓練データ: {X_train.shape}\")\n",
        "  print(f\"検証データ: {X_val.shape}\")\n",
        "  print(f\"テストデータ: {X_test.shape}\")\n",
        "\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "id": "CuGLetDndDsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(X_train, X_val, X_test, y_train, y_val, y_test, batch_size=32):\n",
        "  \"\"\"PyTorchのDataLoaderを作成\"\"\"\n",
        "  # numpy array -> Pytorch Tensor\n",
        "  X_train_tensor = torch.FloatTensor(X_train)\n",
        "  X_val_tensor = torch.FloatTensor(X_val)\n",
        "  X_test_tensor = torch.FloatTensor(X_test)\n",
        "  y_train_tensor = torch.LongTensor(y_train)\n",
        "  y_val_tensor = torch.LongTensor(y_val)\n",
        "  y_test_tensor = torch.LongTensor(y_test)\n",
        "\n",
        "  train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "  val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "  test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "g8HWXHeReiP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmallMLP(nn.Module):\n",
        "  def __init__(self, input_size=784, hidden_size=128, num_classes=10, dropout_rate=0.2):\n",
        "    super(SmallMLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch_size, 28, 28) → (batch_size, 784)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "ybpUCSNw7Ju4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    2層の隠れ層を持つMLP\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=784, hidden1_size=256, hidden2_size=128,\n",
        "                 num_classes=10, dropout_rate=0.2):\n",
        "        super(TwoLayerMLP, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.fc3 = nn.Linear(hidden2_size, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # 第1隠れ層\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # 第2隠れ層\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # 出力層\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "g52uIr9BMD-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_smallmlp_with_params(learning_rate, hidden_size, dropout_rate,\n",
        "                     train_loader, val_loader, epochs=10):\n",
        "    \"\"\"\n",
        "    指定されたハイパーパラメータでモデルを訓練\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    # デバイスの設定\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # print(f\"Using device: {device}\")\n",
        "\n",
        "    # パラメータの制約\n",
        "    learning_rate = max(0.0001, min(0.1, learning_rate / 100))\n",
        "    hidden_size = max(32, min(512, int(hidden_size * 100)))\n",
        "    dropout_rate = max(0.0, min(0.5, dropout_rate / 100))\n",
        "\n",
        "    model = SmallMLP(hidden_size=hidden_size, dropout_rate=dropout_rate)\n",
        "    model = model.to(device)  # モデルをGPUに移動\n",
        "\n",
        "    # 訓練\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = loss.item()\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        # print(f'Epoch [{epoch+1}/{epochs}], ' f'Train Loss: {train_loss:.4f}, ' f'Time: {training_time:.2f}')\n",
        "\n",
        "    # 検証\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            # データをGPUに移動\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    accuracy = correct / total\n",
        "    print(f\"training time: {training_time:.2f}s, accuracy: {accuracy:.4f}\")\n",
        "    return -accuracy  # CMA-ESは最小化なので負の値を返す"
      ],
      "metadata": {
        "id": "u4Gd2k2T80UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_2lmlp_with_params(learning_rate, hidden1_size, hidden2_size, dropout_rate,\n",
        "                     train_loader, val_loader, epochs=10):\n",
        "    \"\"\"\n",
        "    指定されたハイパーパラメータでモデルを訓練\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    # デバイスの設定\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # print(f\"Using device: {device}\")\n",
        "\n",
        "    # パラメータの制約\n",
        "    learning_rate = max(0.0001, min(0.1, learning_rate))\n",
        "    hidden1_size = max(32, min(512, int(hidden1_size)))\n",
        "    hidden2_size = max(32, min(512, int(hidden2_size)))\n",
        "    dropout_rate = max(0.0, min(0.5, dropout_rate))\n",
        "\n",
        "    model = TwoLayerMLP(hidden1_size=hidden1_size, hidden2_size=hidden2_size, dropout_rate=dropout_rate)\n",
        "    model = model.to(device)  # モデルをGPUに移動\n",
        "\n",
        "    # 訓練\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = loss.item()\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        # print(f'Epoch [{epoch+1}/{epochs}], ' f'Train Loss: {train_loss:.4f}, ' f'Time: {training_time:.2f}')\n",
        "\n",
        "    # 検証\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            # データをGPUに移動\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    accuracy = correct / total\n",
        "    print(f\"訓練時間: {training_time:.2f}秒\")\n",
        "    print(f\"正解率: {accuracy}\")\n",
        "    return -accuracy  # CMA-ESは最小化なので負の値を返す"
      ],
      "metadata": {
        "id": "RIKYDDx-MqV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = load_mnist_data()\n",
        "train_loader, val_loader, test_loader = create_data_loaders(X_train, X_val, X_test, y_train, y_val, y_test, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmFtZNMADBOp",
        "outputId": "c1211927-c293-4412-c388-f8320908d191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練データ: (44800, 784)\n",
            "検証データ: (11200, 784)\n",
            "テストデータ: (14000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_smallmlp_with_params(0.001, 256, 0.2, train_loader, val_loader, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et_-3KeDDppt",
        "outputId": "b093497b-ed4d-4e95-9e20-c0e84a2cd2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time: 11.24s, accuracy: 0.9528\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.9527678571428572"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_2lmlp_with_params(0.005, 256, 512, 0.2, train_loader, val_loader, epochs=15)"
      ],
      "metadata": {
        "id": "HKF9PDAhMoJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = [\"learning_rate\", \"hidden_size\", \"dropout_rate\"]\n",
        "fixed_args = {\"train_loader\": train_loader, \"val_loader\": val_loader, \"epochs\": 10}\n",
        "init_point = [1.0, 2.56, 2.0]\n",
        "cmaes = CMAES(arg_names=params, ave_vec=init_point, max_iter=10, fixed_args=fixed_args)"
      ],
      "metadata": {
        "id": "-yPj58m_QZ9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, value = cmaes.opt(train_smallmlp_with_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p19KZhJWAxd",
        "outputId": "c7757c2c-0a9a-4508-f7c7-d51197739359"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====1世代目=====\n",
            "training time: 6.81s, accuracy: 0.9726\n",
            "training time: 7.07s, accuracy: 0.9739\n",
            "training time: 7.06s, accuracy: 0.9283\n",
            "training time: 7.10s, accuracy: 0.9658\n",
            "training time: 7.30s, accuracy: 0.9650\n",
            "training time: 6.57s, accuracy: 0.9339\n",
            "training time: 7.35s, accuracy: 0.9596\n",
            "最小値の更新: \n",
            "値: -0.9739285714285715\n",
            "ベクトル: [0.7078588571313538, 1.563757489762975, 0.7176062004276067]\n",
            "=====2世代目=====\n",
            "training time: 6.85s, accuracy: 0.9622\n",
            "training time: 7.05s, accuracy: 0.9654\n",
            "training time: 7.24s, accuracy: 0.9654\n",
            "training time: 6.82s, accuracy: 0.9264\n",
            "training time: 7.26s, accuracy: 0.9703\n",
            "training time: 6.49s, accuracy: 0.9711\n",
            "training time: 7.24s, accuracy: 0.9675\n",
            "=====3世代目=====\n",
            "training time: 6.96s, accuracy: 0.9762\n",
            "training time: 7.10s, accuracy: 0.9713\n",
            "training time: 7.00s, accuracy: 0.9631\n",
            "training time: 6.72s, accuracy: 0.9768\n",
            "training time: 7.21s, accuracy: 0.9326\n",
            "training time: 6.27s, accuracy: 0.9630\n",
            "training time: 6.96s, accuracy: 0.9697\n",
            "最小値の更新: \n",
            "値: -0.9767857142857143\n",
            "ベクトル: [0.2746164112814802, 2.2230847992305476, 0.2567061841733729]\n",
            "=====4世代目=====\n",
            "training time: 6.93s, accuracy: 0.9733\n",
            "training time: 7.20s, accuracy: 0.9761\n",
            "training time: 7.29s, accuracy: 0.9759\n",
            "training time: 6.44s, accuracy: 0.9771\n",
            "training time: 7.04s, accuracy: 0.9055\n",
            "training time: 6.66s, accuracy: 0.9174\n",
            "training time: 7.35s, accuracy: 0.9682\n",
            "最小値の更新: \n",
            "値: -0.9771428571428571\n",
            "ベクトル: [0.2136132935083101, 3.49927649408328, -1.217489462806845]\n",
            "=====5世代目=====\n",
            "training time: 6.61s, accuracy: 0.9399\n",
            "training time: 7.10s, accuracy: 0.9434\n",
            "training time: 7.26s, accuracy: 0.9302\n",
            "training time: 6.80s, accuracy: 0.9740\n",
            "training time: 6.89s, accuracy: 0.9390\n",
            "training time: 6.63s, accuracy: 0.9338\n",
            "training time: 7.17s, accuracy: 0.9371\n",
            "=====6世代目=====\n",
            "training time: 6.75s, accuracy: 0.9254\n",
            "training time: 6.93s, accuracy: 0.9350\n",
            "training time: 7.22s, accuracy: 0.9237\n",
            "training time: 6.83s, accuracy: 0.9714\n",
            "training time: 7.06s, accuracy: 0.9621\n",
            "training time: 6.71s, accuracy: 0.9306\n",
            "training time: 7.24s, accuracy: 0.9372\n",
            "=====7世代目=====\n",
            "training time: 7.04s, accuracy: 0.9705\n",
            "training time: 6.83s, accuracy: 0.9646\n",
            "training time: 7.26s, accuracy: 0.9352\n",
            "training time: 6.82s, accuracy: 0.9699\n",
            "training time: 7.34s, accuracy: 0.9324\n",
            "training time: 6.56s, accuracy: 0.9709\n",
            "training time: 7.31s, accuracy: 0.9721\n",
            "=====8世代目=====\n",
            "training time: 7.27s, accuracy: 0.9747\n",
            "training time: 6.70s, accuracy: 0.9334\n",
            "training time: 7.11s, accuracy: 0.9725\n",
            "training time: 6.87s, accuracy: 0.9623\n",
            "training time: 7.20s, accuracy: 0.9371\n",
            "training time: 6.94s, accuracy: 0.9702\n",
            "training time: 6.99s, accuracy: 0.9659\n",
            "=====9世代目=====\n",
            "training time: 7.29s, accuracy: 0.9610\n",
            "training time: 6.70s, accuracy: 0.9696\n",
            "training time: 7.25s, accuracy: 0.9779\n",
            "training time: 6.38s, accuracy: 0.9742\n",
            "training time: 7.25s, accuracy: 0.9685\n",
            "training time: 6.98s, accuracy: 0.9712\n",
            "training time: 6.82s, accuracy: 0.9665\n",
            "最小値の更新: \n",
            "値: -0.9778571428571429\n",
            "ベクトル: [0.2844775778363134, 3.4931197031262182, 0.4560618736564812]\n",
            "=====10世代目=====\n",
            "training time: 7.24s, accuracy: 0.9408\n",
            "training time: 6.77s, accuracy: 0.9721\n",
            "training time: 7.33s, accuracy: 0.9703\n",
            "training time: 6.46s, accuracy: 0.9668\n",
            "training time: 7.21s, accuracy: 0.9766\n",
            "training time: 7.06s, accuracy: 0.9357\n",
            "training time: 6.80s, accuracy: 0.9699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq7OI5cqhe6T",
        "outputId": "43605246-5627-4b5c-c4a3-c51416c40255"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2844775778363134, 3.4931197031262182, 0.4560618736564812]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_smallmlp_with_params(value[0], value[1], value[2], train_loader, val_loader, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqxZPnuYhipV",
        "outputId": "2a000b68-f7d0-47e2-fa81-faf8c627b085"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time: 11.05s, accuracy: 0.9754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.9753571428571428"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    }
  ]
}